{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentences(path: str):\n",
    "    chunks = []\n",
    "    with open(path) as file:\n",
    "        for line in file.readlines():\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                chunks.append(line)\n",
    "    return chunks\n",
    "\n",
    "meditations = '../data/meditations.txt'\n",
    "chunks = load_sentences(meditations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/garrett.partenza/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/garrett.partenza/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/garrett.partenza/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(chunk: str):\n",
    "    chunk = chunk.lower()\n",
    "    chunk = re.sub(r'[^a-z\\s]', '', chunk)\n",
    "    tokens = word_tokenize(chunk)\n",
    "    cleaned_tokens = [\n",
    "        lemmatizer.lemmatize(word) for word in tokens\n",
    "        if word not in stop_words and word not in punctuation\n",
    "    ]\n",
    "    cleaned_chunk = ' '.join(cleaned_tokens)\n",
    "    return cleaned_chunk\n",
    "\n",
    "chunks_clean = list(clean_text(chunk) for chunk in chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "corpus = list(chunk.split() for chunk in chunks_clean)\n",
    "\n",
    "model = FastText(\n",
    "    corpus,\n",
    "    vector_size=265,\n",
    "    window=8,\n",
    "    min_count=1,\n",
    "    sg=0,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "model.save(\"word2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def embed_chunk(chunk: str, model):\n",
    "    embeddings = list(model.wv[word] for word in chunk.split())\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "\n",
    "model = FastText.load(\"word2vec_model\")\n",
    "vectors = list(embed_chunk(chunk, model) for chunk in chunks_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>chunk_clean</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From my grandfather Verus I learned good moral...</td>\n",
       "      <td>grandfather verus learned good moral governmen...</td>\n",
       "      <td>[-0.116709344, 0.471837, 0.047672816, -0.34095...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From the reputation and remembrance of my fath...</td>\n",
       "      <td>reputation remembrance father modesty manly ch...</td>\n",
       "      <td>[-0.15210967, 0.614254, 0.062129255, -0.444069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From my mother, piety and beneficence, and abs...</td>\n",
       "      <td>mother piety beneficence abstinence evil deed ...</td>\n",
       "      <td>[-0.13348334, 0.53843445, 0.054877356, -0.3895...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From my great-grandfather, not to have frequen...</td>\n",
       "      <td>greatgrandfather frequented public school good...</td>\n",
       "      <td>[-0.13885155, 0.56063956, 0.056867585, -0.4056...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From my governor, to be neither of the green n...</td>\n",
       "      <td>governor neither green blue party game circus ...</td>\n",
       "      <td>[-0.1011597, 0.40916425, 0.041610878, -0.29586...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chunk  \\\n",
       "0  From my grandfather Verus I learned good moral...   \n",
       "1  From the reputation and remembrance of my fath...   \n",
       "2  From my mother, piety and beneficence, and abs...   \n",
       "3  From my great-grandfather, not to have frequen...   \n",
       "4  From my governor, to be neither of the green n...   \n",
       "\n",
       "                                         chunk_clean  \\\n",
       "0  grandfather verus learned good moral governmen...   \n",
       "1  reputation remembrance father modesty manly ch...   \n",
       "2  mother piety beneficence abstinence evil deed ...   \n",
       "3  greatgrandfather frequented public school good...   \n",
       "4  governor neither green blue party game circus ...   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.116709344, 0.471837, 0.047672816, -0.34095...  \n",
       "1  [-0.15210967, 0.614254, 0.062129255, -0.444069...  \n",
       "2  [-0.13348334, 0.53843445, 0.054877356, -0.3895...  \n",
       "3  [-0.13885155, 0.56063956, 0.056867585, -0.4056...  \n",
       "4  [-0.1011597, 0.40916425, 0.041610878, -0.29586...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "database = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"chunk\": chunks,\n",
    "        \"chunk_clean\": chunks_clean,\n",
    "        \"vector\": vectors\n",
    "    }\n",
    ")\n",
    "\n",
    "database.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That which has died falls not out of the universe. If it stays here, it also changes here, and is dissolved into its proper parts, which are elements of the universe and of thyself. And these too change, and they murmur not.\n",
      "The nature of the An moved to make the universe. But now either everything that takes place comes by way of consequence or continuity; or even the chief things towards which the ruling power of the universe directs its own movement are governed by no rational principle. If this is remembered it will make thee more tranquil in many things.\n",
      "From Rusticus I received the impression that my character required improvement and discipline; and from him I learned not to be led astray to sophistic emulation, nor to writing on speculative matters, nor to delivering little hortatory orations, nor to showing myself off as a man who practises much discipline, or does benevolent acts in order to make a display; and to abstain from rhetoric, and poetry, and fine writing; and not to walk about in the house in my outdoor dress, nor to do other things of the kind; and to write my letters with simplicity, like the letter which Rusticus wrote from Sinuessa to my mother; and with respect to those who have offended me by words, or done me wrong, to be easily disposed to be pacified and reconciled, as soon as they have shown a readiness to be reconciled; and to read carefully, and not to be satisfied with a superficial understanding of a book; nor hastily to give my assent to those who talk overmuch; and I am indebted to him for being acquainted with the discourses of Epictetus, which he communicated to me out of his own collection.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query = \"universe, planets, and stars\"\n",
    "top_k = 3\n",
    "\n",
    "query_vector = embed_chunk(clean_text(query), model)\n",
    "\n",
    "similarity_scores = cosine_similarity([query_vector], database.vector.to_list())[0]\n",
    "similarity_pairs = list(zip(database.chunk, similarity_scores))\n",
    "results = sorted(similarity_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top_k_results = []\n",
    "for k in range(top_k):\n",
    "    print(results[k][0])\n",
    "    top_k_results.append(results[k][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote: \"That which has died falls not out of the universe. If it stays here, it also changes here, and is dissolved into its proper parts, which are elements of the universe and of thyself.\"\n",
      "\n",
      "Interpretation: This quote suggests that everything within the universe is interconnected and eternal, including our own lives and experiences. The user's concern about the universe, planets, and stars may be related to their understanding of the vastness and mystery of existence.\n",
      "\n",
      "Advice: Reflect on your place within this grand scheme, recognizing that even after death, your essence remains a part of the universe. This perspective can bring tranquility and acceptance in the face of uncertainty.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def generate_prompts(query, results):\n",
    "    system_prompt = (\n",
    "        \"<system_prompt>\"\n",
    "        \"You are a Stoic AI assistant, deeply versed in the teachings of Marcus Aurelius. \"\n",
    "        \"Your job is to follow the user's task exactly, not straying from any of the directions provided to you.\"\n",
    "        \"</system_prompt>\"\n",
    "    )\n",
    "\n",
    "    task_xml = (\n",
    "        \"<task>\"\n",
    "        \"Analyze the following user query and the provided quotes from Marcus Aurelius' Meditations. \"\n",
    "        \"Select the most relevant quote that addresses the user's concern. Structure your response as follows:\"\n",
    "        \"<instructions>\"\n",
    "        \"<step>Quote: Begin with the chosen quote, enclosed in quotation marks.</step>\"\n",
    "        \"<step>Do not hallucinate the chosen quote, you must choose one from the given results.</step>\"\n",
    "        \"<step>Interpretation: In 2-3 sentences, explain how this quote relates to the user's query.</step>\"\n",
    "        \"<step>Advice: In 1-2 sentences, offer practical guidance based on the quote and Stoic principles.</step>\"\n",
    "        \"<step>Do not write more than a few sentences outside of the selected quote.</step>\"\n",
    "        \"<step>Do not discuss anything about stoicism outside of the quote and query.</step>\"\n",
    "        \"</instructions>\"\n",
    "        \"Maintain a wise and compassionate tone throughout your response.\"\n",
    "        \"</task>\"\n",
    "    )\n",
    "\n",
    "    query_xml = f\"<rag_query>{query}</rag_query>\"\n",
    "\n",
    "    search_results_xml = \"<search_results>\" + \"\".join(\n",
    "        f\"<search_result>{result}</search_result>\" for result in results\n",
    "    ) + \"</search_results>\"\n",
    "\n",
    "    user_prompt = f\"<user_prompt>{task_xml}{query_xml}{search_results_xml}</user_prompt>\"\n",
    "\n",
    "    return system_prompt, user_prompt\n",
    "\n",
    "def stoic_guide(system_prompt, user_prompt):\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='llama3:instruct',\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response['message']['content']\n",
    "\n",
    "system_prompt, user_prompt = generate_prompts(query, top_k_results)\n",
    "print(stoic_guide(system_prompt, user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
