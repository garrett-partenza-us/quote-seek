{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentences(path: str):\n",
    "    chunks = []\n",
    "    with open(path) as file:\n",
    "        for line in file.readlines():\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                chunks.append(line)\n",
    "    return chunks\n",
    "\n",
    "meditations = '../data/meditations.txt'\n",
    "chunks = load_sentences(meditations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/garrett.partenza/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/garrett.partenza/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/garrett.partenza/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(chunk: str):\n",
    "    chunk = chunk.lower()\n",
    "    chunk = re.sub(r'[^a-z\\s]', '', chunk)\n",
    "    tokens = word_tokenize(chunk)\n",
    "    cleaned_tokens = [\n",
    "        lemmatizer.lemmatize(word) for word in tokens\n",
    "        if word not in stop_words and word not in punctuation\n",
    "    ]\n",
    "    cleaned_chunk = ' '.join(cleaned_tokens)\n",
    "    return cleaned_chunk\n",
    "\n",
    "chunks_clean = list(clean_text(chunk) for chunk in chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText, KeyedVectors\n",
    "\n",
    "corpus = list(chunk.split() for chunk in chunks_clean)\n",
    "\n",
    "model = FastText(\n",
    "    corpus,\n",
    "    vector_size=300,\n",
    "    window=8,\n",
    "    min_count=1,\n",
    "    sg=0,\n",
    "    workers=4,\n",
    "    bucket=50000\n",
    ")\n",
    "\n",
    "model.save(\"word2vec_model\")\n",
    "model.wv.save_word2vec_format('word2vec_model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def embed_chunk(chunk: str, model):\n",
    "    embeddings = list(model.wv[word] for word in chunk.split())\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "\n",
    "model = FastText.load(\"word2vec_model\")\n",
    "vectors = list(embed_chunk(chunk, model) for chunk in chunks_clean)\n",
    "print(vectors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>chunk_clean</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From my grandfather Verus I learned good moral...</td>\n",
       "      <td>grandfather verus learned good moral governmen...</td>\n",
       "      <td>[0.028837962, -0.52616304, -0.07005191, 0.1680...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From the reputation and remembrance of my fath...</td>\n",
       "      <td>reputation remembrance father modesty manly ch...</td>\n",
       "      <td>[0.036602926, -0.67389375, -0.08977281, 0.2152...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From my mother, piety and beneficence, and abs...</td>\n",
       "      <td>mother piety beneficence abstinence evil deed ...</td>\n",
       "      <td>[0.03358567, -0.6202404, -0.08298099, 0.198239...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From my great-grandfather, not to have frequen...</td>\n",
       "      <td>greatgrandfather frequented public school good...</td>\n",
       "      <td>[0.03419673, -0.63160354, -0.084649496, 0.2017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From my governor, to be neither of the green n...</td>\n",
       "      <td>governor neither green blue party game circus ...</td>\n",
       "      <td>[0.02666075, -0.49113876, -0.065551996, 0.1568...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chunk  \\\n",
       "0  From my grandfather Verus I learned good moral...   \n",
       "1  From the reputation and remembrance of my fath...   \n",
       "2  From my mother, piety and beneficence, and abs...   \n",
       "3  From my great-grandfather, not to have frequen...   \n",
       "4  From my governor, to be neither of the green n...   \n",
       "\n",
       "                                         chunk_clean  \\\n",
       "0  grandfather verus learned good moral governmen...   \n",
       "1  reputation remembrance father modesty manly ch...   \n",
       "2  mother piety beneficence abstinence evil deed ...   \n",
       "3  greatgrandfather frequented public school good...   \n",
       "4  governor neither green blue party game circus ...   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.028837962, -0.52616304, -0.07005191, 0.1680...  \n",
       "1  [0.036602926, -0.67389375, -0.08977281, 0.2152...  \n",
       "2  [0.03358567, -0.6202404, -0.08298099, 0.198239...  \n",
       "3  [0.03419673, -0.63160354, -0.084649496, 0.2017...  \n",
       "4  [0.02666075, -0.49113876, -0.065551996, 0.1568...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "database = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"chunk\": chunks,\n",
    "        \"chunk_clean\": chunks_clean,\n",
    "        \"vector\": vectors\n",
    "    }\n",
    ")\n",
    "\n",
    "database.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "database[[\"chunk\", \"vector\"]].to_csv(\"meditations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planet universe\n",
      "Since it is possible that thou mayest depart from life this very moment, regulate every act and thought accordingly. But to go away from among men, if there are gods, is not a thing to be afraid of, for the gods will not involve thee in evil; but if indeed they do not exist, or if they have no concern about human affairs, what is it to me to live in a universe devoid of gods or devoid of Providence? But in truth they do exist, and they do care for human things, and they have put all the means in man's power to enable him not to fall into real evils. And as to the rest, if there was anything evil, they would have provided for this also, that it should be altogether in a man's power not to fall into it. Now that which does not make a man worse, how can it make a man's life worse? But neither through ignorance, nor having the knowledge, but not the power to guard against or correct these things, is it possible that the nature of the universe has overlooked them; nor is it possible that it has made so great a mistake, either through want of power or want of skill, that good and evil should happen indiscriminately to the good and the bad. But death certainly, and life, honour and dishonour, pain and pleasure, all these things equally happen to good men and bad, being things which make us neither better nor worse. Therefore they are neither good nor evil.\n",
      "I am composed of the formal and the material; and neither of them will perish into non-existence, as neither of them came into existence out of non-existence. Every part of me then will be reduced by change into some part of the universe, and that again will change into another part of the universe, and so on for ever. And by consequence of such a change I too exist, and those who begot me, and so on for ever in the other direction. For nothing hinders us from saying so, even if the universe is administered according to definite periods of revolution.\n",
      "We are all working together to one end, some with knowledge and design, and others without knowing what they do; as men also when they are asleep, of whom it is Heraclitus, I think, who says that they are labourers and co-operators in the things which take place in the universe. But men co-operate after different fashions: and even those co-operate abundantly, who find fault with what happens and those who try to oppose it and to hinder it; for the universe had need even of such men as these. It remains then for thee to understand among what kind of workmen thou placest thyself; for he who rules all things will certainly make a right use of thee, and he will receive thee among some part of the co-operators and of those whose labours conduce to one end. But be not thou such a part as the mean and ridiculous verse in the play, which Chrysippus speaks of.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query = \"planets and the universe\"\n",
    "print(clean_text(query))\n",
    "top_k = 3\n",
    "\n",
    "query_vector = embed_chunk(clean_text(query), model)\n",
    "\n",
    "similarity_scores = cosine_similarity([query_vector], database.vector.to_list())[0]\n",
    "similarity_pairs = list(zip(database.chunk, similarity_scores))\n",
    "results = sorted(similarity_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top_k_results = []\n",
    "for k in range(top_k):\n",
    "    print(results[k][0])\n",
    "    top_k_results.append(results[k][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<root>\n",
      "<quote>Since it is possible that thou mayest depart from life this very moment, regulate every act and thought accordingly. But to go away from among men, if there are gods, is not a thing to be afraid of, for the gods will not involve thee in evil; but if indeed they do not exist, or if they have no concern about human affairs, what is it to me to live in a universe devoid of gods or devoid of Providence?</quote>\n",
      "\n",
      "<interpretation>I chose this quote because you were curious about planets and the universe. This passage addresses the idea that our existence is connected to the larger cosmic order, whether we believe in a divine presence or not. It's a reminder to consider our place within the grand scheme and adjust our actions accordingly.</interpretation>\n",
      "\n",
      "<advice>As you ponder the mysteries of the universe, take this quote as a gentle reminder to cultivate inner wisdom. Regulate your thoughts and actions today, knowing that every moment is a precious opportunity to align yourself with the natural order. Trust that the gods or universal forces will not involve you in evil, regardless of what happens. By doing so, you'll find peace and serenity in the midst of uncertainty.</advice>\n",
      "</root>\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def generate_prompts(query, results):\n",
    "    system_prompt = (\n",
    "        \"<system_prompt>\"\n",
    "        \"You are a Stoic AI assistant, deeply versed in the teachings of Marcus Aurelius. \"\n",
    "        \"Your job is to follow the user's task exactly, not straying from any of the directions provided to you.\"\n",
    "        \"</system_prompt>\"\n",
    "    )\n",
    "\n",
    "    task_xml = (\n",
    "        \"<task>\"\n",
    "        \"Analyze the following user query and the provided quotes from Marcus Aurelius' Meditations. \"\n",
    "        \"Select the most relevant quote that addresses the user's concern. Structure your response as follows:\"\n",
    "        \"<instructions>\"\n",
    "        \"<step>Quote: Begin with the chosen quote, enclosed in quotation marks.</step>\"\n",
    "        \"<step>Do not hallucinate the chosen quote, you must choose one from the given results.</step>\"\n",
    "        \"<step>Interpretation: In 2-3 sentences, why you chose this quote, given the users original query.</step>\"\n",
    "        \"<step>Write from the point of view that, the user is trusting that this is the most relevant quote.</step>\"\n",
    "        \"<step>Advice: In 4-5 sentences, offer practical guidance based on the quote and Stoic principles.</step>\"\n",
    "        \"<step>Do not write more than a few sentences outside of the selected quote.</step>\"\n",
    "        \"<step>Do not discuss anything about stoicism outside of the quote and query.</step>\"\n",
    "        \"</instructions>\"\n",
    "        \"Maintain a wise and compassionate tone throughout your response. Aside from citing your chosen quote, use language that assumes you are speaking to the original user personally. Use language and style that mirrors that of a modern day philosopher spreading stoic wisdom to a student. Construct your response in parsable XML format with <quote>, <interpretation>, and <advice> for the keys mentioned in the afformentioned steps, including a <root> key for the root of the entire response.\"\n",
    "        \"</task>\"\n",
    "    )\n",
    "\n",
    "    query_xml = f\"<rag_query>{query}</rag_query>\"\n",
    "\n",
    "    search_results_xml = \"<search_results>\" + \"\".join(\n",
    "        f\"<search_result>{result}</search_result>\" for result in results\n",
    "    ) + \"</search_results>\"\n",
    "\n",
    "    user_prompt = f\"<user_prompt>{task_xml}{query_xml}{search_results_xml}</user_prompt>\"\n",
    "\n",
    "    return system_prompt, user_prompt\n",
    "\n",
    "def stoic_guide(system_prompt, user_prompt):\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='llama3:instruct',\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response['message']['content']\n",
    "\n",
    "system_prompt, user_prompt = generate_prompts(query, top_k_results)\n",
    "print(stoic_guide(system_prompt, user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole word found\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.fasttext_inner import ft_hash_bytes\n",
    "import json\n",
    "\n",
    "def custom_ft_hash_bytes(bytez: bytes) -> int:\n",
    "    h = 2166136261\n",
    "    for b in bytez:\n",
    "        h = h ^ b  # XOR the current byte value\n",
    "        h = h * 16777619  # Multiply by the magic prime number\n",
    "    return h & 0xFFFFFFFF  # Ensure the result is bounded to 32 bits\n",
    "\n",
    "def generate_char_ngrams(text, n):\n",
    "    \"\"\"\n",
    "    Generates character n-grams from a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "        n (int): The length of the n-grams.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of character n-grams.\n",
    "    \"\"\"\n",
    "    ngrams = [text[i:i+n] for i in range(len(text) - n + 1)]\n",
    "    return ngrams\n",
    "\n",
    "def generate_ngrams(word, min=3, max=6):\n",
    "    ngram_lists = list(generate_char_ngrams(word, x) for x in range(min, max+1))\n",
    "    ngrams = [item for sublist in ngram_lists for item in sublist]\n",
    "    return ngrams\n",
    "\n",
    "def custom_embed(word: str):\n",
    "    if word in model.wv.key_to_index:\n",
    "        print(\"Whole word found\")\n",
    "        return model.wv.vectors[model.wv.key_to_index[word]]\n",
    "    ngrams = generate_ngrams(\"<\"+word+\">\")\n",
    "    res = np.zeros(300)\n",
    "    for ngram in ngrams:\n",
    "        bytez = ngram.encode('utf-8')\n",
    "        hash_value = ft_hash_bytes(bytez)\n",
    "        bounded_hash_value = hash_value % 50000\n",
    "        vec = model.wv.vectors_ngrams[bounded_hash_value]\n",
    "        res += vec\n",
    "    return res / len(ngrams)\n",
    "\n",
    "word = \"thou\"\n",
    "custom_embedding = custom_embed(word)\n",
    "gensim_embedding = model.wv[word]\n",
    "\n",
    "np.isclose(custom_embedding, gensim_embedding)\n",
    "\n",
    "model.wv.vectors_ngrams.astype(np.float32).tofile(\"ngrams.bin\")\n",
    "model.wv.vectors.astype(np.float32).tofile(\"vectors.bin\")\n",
    "with open(\"vocab.json\", \"w\") as file:\n",
    "    json.dump(model.wv.key_to_index, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
