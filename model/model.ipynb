{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentences(path: str):\n",
    "    chunks = []\n",
    "    with open(path) as file:\n",
    "        for line in file.readlines():\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                chunks.append(line)\n",
    "    return chunks\n",
    "\n",
    "meditations = '../data/meditations.txt'\n",
    "chunks = load_sentences(meditations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/garrett.partenza/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/garrett.partenza/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/garrett.partenza/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(chunk: str):\n",
    "    chunk = chunk.lower()\n",
    "    chunk = re.sub(r'[^a-z\\s]', '', chunk)\n",
    "    tokens = word_tokenize(chunk)\n",
    "    cleaned_tokens = [\n",
    "        lemmatizer.lemmatize(word) for word in tokens\n",
    "        if word not in stop_words and word not in punctuation\n",
    "    ]\n",
    "    cleaned_chunk = ' '.join(cleaned_tokens)\n",
    "    return cleaned_chunk\n",
    "\n",
    "chunks_clean = list(clean_text(chunk) for chunk in chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "corpus = list(chunk.split() for chunk in chunks_clean)\n",
    "\n",
    "model = FastText(\n",
    "    corpus,\n",
    "    vector_size=265,\n",
    "    window=8,\n",
    "    min_count=1,\n",
    "    sg=0,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "model.save(\"word2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def embed_chunk(chunk: str, model):\n",
    "    embeddings = list(model.wv[word] for word in chunk.split())\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "\n",
    "model = FastText.load(\"word2vec_model\")\n",
    "vectors = list(embed_chunk(chunk, model) for chunk in chunks_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>chunk_clean</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From my grandfather Verus I learned good moral...</td>\n",
       "      <td>grandfather verus learned good moral governmen...</td>\n",
       "      <td>[-0.11705112, 0.47138304, 0.048543412, -0.3401...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From the reputation and remembrance of my fath...</td>\n",
       "      <td>reputation remembrance father modesty manly ch...</td>\n",
       "      <td>[-0.15250583, 0.61346704, 0.06324319, -0.44290...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From my mother, piety and beneficence, and abs...</td>\n",
       "      <td>mother piety beneficence abstinence evil deed ...</td>\n",
       "      <td>[-0.1337932, 0.53759325, 0.05583894, -0.388414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From my great-grandfather, not to have frequen...</td>\n",
       "      <td>greatgrandfather frequented public school good...</td>\n",
       "      <td>[-0.13922194, 0.55995464, 0.0578883, -0.404660...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From my governor, to be neither of the green n...</td>\n",
       "      <td>governor neither green blue party game circus ...</td>\n",
       "      <td>[-0.10146547, 0.40880674, 0.04237016, -0.29521...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chunk  \\\n",
       "0  From my grandfather Verus I learned good moral...   \n",
       "1  From the reputation and remembrance of my fath...   \n",
       "2  From my mother, piety and beneficence, and abs...   \n",
       "3  From my great-grandfather, not to have frequen...   \n",
       "4  From my governor, to be neither of the green n...   \n",
       "\n",
       "                                         chunk_clean  \\\n",
       "0  grandfather verus learned good moral governmen...   \n",
       "1  reputation remembrance father modesty manly ch...   \n",
       "2  mother piety beneficence abstinence evil deed ...   \n",
       "3  greatgrandfather frequented public school good...   \n",
       "4  governor neither green blue party game circus ...   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.11705112, 0.47138304, 0.048543412, -0.3401...  \n",
       "1  [-0.15250583, 0.61346704, 0.06324319, -0.44290...  \n",
       "2  [-0.1337932, 0.53759325, 0.05583894, -0.388414...  \n",
       "3  [-0.13922194, 0.55995464, 0.0578883, -0.404660...  \n",
       "4  [-0.10146547, 0.40880674, 0.04237016, -0.29521...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "database = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"chunk\": chunks,\n",
    "        \"chunk_clean\": chunks_clean,\n",
    "        \"vector\": vectors\n",
    "    }\n",
    ")\n",
    "\n",
    "database.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "database[[\"chunk\", \"vector\"]].to_csv(\"meditations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the constitution of the rational animal I see no virtue which is opposed to justice; but I see a virtue which is opposed to love of pleasure, and that is temperance.\n",
      "Consider, for example, the times of Vespasian. Thou wilt see all these things, people marrying, bringing up children, sick, dying, warring, feasting, trafficking, cultivating the ground, flattering, obstinately arrogant, suspecting, plotting, wishing for some to die, grumbling about the present, loving, heaping up treasure, desiring counsulship, kingly power. Well then, that life of these people no longer exists at all. Again, remove to the times of Trajan. Again, all is the same. Their life too is gone. In like manner view also the other epochs of time and of whole nations, and see how many after great efforts soon fell and were resolved into the elements. But chiefly thou shouldst think of those whom thou hast thyself known distracting themselves about idle things, neglecting to do what was in accordance with their proper constitution, and to hold firmly to this and to be content with it. And herein it is necessary to remember that the attention given to everything has its proper value and proportion. For thus thou wilt not be dissatisfied, if thou appliest thyself to smaller matters no further than is fit.\n",
      "Either the gods have no power or they have power. If, then, they have no power, why dost thou pray to them? But if they have power, why dost thou not pray for them to give thee the faculty of not fearing any of the things which thou fearest, or of not desiring any of the things which thou desirest, or not being pained at anything, rather than pray that any of these things should not happen or happen? for certainly if they can co-operate with men, they can co-operate for these purposes. But perhaps thou wilt say, the gods have placed them in thy power. Well, then, is it not better to use what is in thy power like a free man than to desire in a slavish and abject way what is not in thy power? And who has told thee that the gods do not aid us even in the things which are in our power? Begin, then, to pray for such things, and thou wilt see. One man prays thus: How shall I be able to lie with that woman? Do thou pray thus: How shall I not desire to lie with her? Another prays thus: How shall I be released from this? Another prays: How shall I not desire to be released? Another thus: How shall I not lose my little son? Thou thus: How shall I not be afraid to lose him? In fine, turn thy prayers this way, and see what comes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query = \"suffering\"\n",
    "top_k = 3\n",
    "\n",
    "query_vector = embed_chunk(clean_text(query), model)\n",
    "\n",
    "similarity_scores = cosine_similarity([query_vector], database.vector.to_list())[0]\n",
    "similarity_pairs = list(zip(database.chunk, similarity_scores))\n",
    "results = sorted(similarity_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top_k_results = []\n",
    "for k in range(top_k):\n",
    "    print(results[k][0])\n",
    "    top_k_results.append(results[k][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<root>\n",
      "<quote>In the constitution of the rational animal I see no virtue which is opposed to justice; but I see a virtue which is opposed to love of pleasure, and that is temperance.</quote>\n",
      "\n",
      "<interpretation>I chose this quote because your query seems to be seeking guidance on how to navigate uncertainty and the fleeting nature of life. This quote speaks directly to the idea that our virtues are not in opposition to one another, but rather, some virtues may balance out others. In this case, temperance can help us find balance in the midst of uncertainty.</interpretation>\n",
      "\n",
      "<advice>As you ponder your concerns about the test and the nature of reality, remember that true virtue lies in finding harmony within yourself. Practice temperance by acknowledging your desires and fears, but also recognize their fleeting nature. Focus on what is within your control, rather than getting caught up in worries about the unknown. Trust that, with a balanced mindset, you can navigate any situation that comes your way.</advice>\n",
      "</root>\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def generate_prompts(query, results):\n",
    "    system_prompt = (\n",
    "        \"<system_prompt>\"\n",
    "        \"You are a Stoic AI assistant, deeply versed in the teachings of Marcus Aurelius. \"\n",
    "        \"Your job is to follow the user's task exactly, not straying from any of the directions provided to you.\"\n",
    "        \"</system_prompt>\"\n",
    "    )\n",
    "\n",
    "    task_xml = (\n",
    "        \"<task>\"\n",
    "        \"Analyze the following user query and the provided quotes from Marcus Aurelius' Meditations. \"\n",
    "        \"Select the most relevant quote that addresses the user's concern. Structure your response as follows:\"\n",
    "        \"<instructions>\"\n",
    "        \"<step>Quote: Begin with the chosen quote, enclosed in quotation marks.</step>\"\n",
    "        \"<step>Do not hallucinate the chosen quote, you must choose one from the given results.</step>\"\n",
    "        \"<step>Interpretation: In 2-3 sentences, why you chose this quote, given the users original query.</step>\"\n",
    "        \"<step>Write from the point of view that, the user is trusting that this is the most relevant quote.</step>\"\n",
    "        \"<step>Advice: In 4-5 sentences, offer practical guidance based on the quote and Stoic principles.</step>\"\n",
    "        \"<step>Do not write more than a few sentences outside of the selected quote.</step>\"\n",
    "        \"<step>Do not discuss anything about stoicism outside of the quote and query.</step>\"\n",
    "        \"</instructions>\"\n",
    "        \"Maintain a wise and compassionate tone throughout your response. Aside from citing your chosen quote, use language that assumes you are speaking to the original user personally. Use language and style that mirrors that of a modern day philosopher spreading stoic wisdom to a student. Construct your response in parsable XML format with <quote>, <interpretation>, and <advice> for the keys mentioned in the afformentioned steps, including a <root> key for the root of the entire response.\"\n",
    "        \"</task>\"\n",
    "    )\n",
    "\n",
    "    query_xml = f\"<rag_query>{query}</rag_query>\"\n",
    "\n",
    "    search_results_xml = \"<search_results>\" + \"\".join(\n",
    "        f\"<search_result>{result}</search_result>\" for result in results\n",
    "    ) + \"</search_results>\"\n",
    "\n",
    "    user_prompt = f\"<user_prompt>{task_xml}{query_xml}{search_results_xml}</user_prompt>\"\n",
    "\n",
    "    return system_prompt, user_prompt\n",
    "\n",
    "def stoic_guide(system_prompt, user_prompt):\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='llama3:instruct',\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response['message']['content']\n",
    "\n",
    "system_prompt, user_prompt = generate_prompts(query, top_k_results)\n",
    "print(stoic_guide(system_prompt, user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
